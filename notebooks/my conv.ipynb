{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d6f36c",
   "metadata": {},
   "source": [
    "The performance gap is huge: https://twitter.com/bwasti/status/1449922665360338945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8eba2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d9ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "67b98da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function _pad in module torch.nn.functional:\n",
      "\n",
      "_pad(input: torch.Tensor, pad: List[int], mode: str = 'constant', value: float = 0) -> torch.Tensor\n",
      "    Pads tensor.\n",
      "    \n",
      "    Padding size:\n",
      "        The padding size by which to pad some dimensions of :attr:`input`\n",
      "        are described starting from the last dimension and moving forward.\n",
      "        :math:`\\left\\lfloor\\frac{\\text{len(pad)}}{2}\\right\\rfloor` dimensions\n",
      "        of ``input`` will be padded.\n",
      "        For example, to pad only the last dimension of the input tensor, then\n",
      "        :attr:`pad` has the form\n",
      "        :math:`(\\text{padding\\_left}, \\text{padding\\_right})`;\n",
      "        to pad the last 2 dimensions of the input tensor, then use\n",
      "        :math:`(\\text{padding\\_left}, \\text{padding\\_right},`\n",
      "        :math:`\\text{padding\\_top}, \\text{padding\\_bottom})`;\n",
      "        to pad the last 3 dimensions, use\n",
      "        :math:`(\\text{padding\\_left}, \\text{padding\\_right},`\n",
      "        :math:`\\text{padding\\_top}, \\text{padding\\_bottom}`\n",
      "        :math:`\\text{padding\\_front}, \\text{padding\\_back})`.\n",
      "    \n",
      "    Padding mode:\n",
      "        See :class:`torch.nn.ConstantPad2d`, :class:`torch.nn.ReflectionPad2d`, and\n",
      "        :class:`torch.nn.ReplicationPad2d` for concrete examples on how each of the\n",
      "        padding modes works. Constant padding is implemented for arbitrary dimensions.\n",
      "        Replicate padding is implemented for padding the last 3 dimensions of 5D input\n",
      "        tensor, or the last 2 dimensions of 4D input tensor, or the last dimension of\n",
      "        3D input tensor. Reflect padding is only implemented for padding the last 2\n",
      "        dimensions of 4D input tensor, or the last dimension of 3D input tensor.\n",
      "    \n",
      "    Note:\n",
      "        When using the CUDA backend, this operation may induce nondeterministic\n",
      "        behaviour in its backward pass that is not easily switched off.\n",
      "        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): N-dimensional tensor\n",
      "        pad (tuple): m-elements tuple, where\n",
      "            :math:`\\frac{m}{2} \\leq` input dimensions and :math:`m` is even.\n",
      "        mode: ``'constant'``, ``'reflect'``, ``'replicate'`` or ``'circular'``.\n",
      "            Default: ``'constant'``\n",
      "        value: fill value for ``'constant'`` padding. Default: ``0``\n",
      "    \n",
      "    Examples::\n",
      "    \n",
      "        >>> t4d = torch.empty(3, 3, 4, 2)\n",
      "        >>> p1d = (1, 1) # pad last dim by 1 on each side\n",
      "        >>> out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n",
      "        >>> print(out.size())\n",
      "        torch.Size([3, 3, 4, 4])\n",
      "        >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)\n",
      "        >>> out = F.pad(t4d, p2d, \"constant\", 0)\n",
      "        >>> print(out.size())\n",
      "        torch.Size([3, 3, 8, 4])\n",
      "        >>> t4d = torch.empty(3, 3, 4, 2)\n",
      "        >>> p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)\n",
      "        >>> out = F.pad(t4d, p3d, \"constant\", 0)\n",
      "        >>> print(out.size())\n",
      "        torch.Size([3, 9, 7, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(f.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d1c8bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buck_pad(inp, pad: int):\n",
    "    inp_height, inp_width = inp.shape\n",
    "    return th.cat([th.zeros([pad, inp_width + pad * 2]),\n",
    "                  th.cat([th.zeros([inp_height, pad]), inp, th.zeros([inp_height, pad])], dim=1),\n",
    "                  th.zeros([pad, inp_width + pad * 2])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "5724e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buck_pad(th.ones(4, 4), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fcbcd8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctionsClass.cat>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a3253f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctionsClass.conv1d>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "ba615fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 5\n",
    "C_in = 4\n",
    "C_out = 4\n",
    "LEN = 10\n",
    "WINDOW_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "290e9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.randn(B, C_in, LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "f340790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = th.randn(C_out, C_in, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "5a483b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 1)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "facd75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buck_conv1d(inp, weight, stride=1, dilation=1, groups=1):\n",
    "    B, C_in, LEN = inp.shape\n",
    "    C_out, C_in2, WINDOW_SIZE = weight.shape\n",
    "    assert C_in == C_in2 * groups, (C_in, C_in2 * groups)\n",
    "    size = [B, groups, C_in2, (LEN - ((WINDOW_SIZE - 1) * dilation)) // stride, WINDOW_SIZE]\n",
    "    stride = [LEN * C_in, LEN * C_in2, LEN, stride, dilation]\n",
    "    strided_x_dilated = inp.as_strided(size=size, stride=stride)\n",
    "    \n",
    "    return th.einsum('bgcnw,gdcw->bgdn', strided_x_dilated, weight.reshape([groups, C_out//groups, C_in2, WINDOW_SIZE])\n",
    "                    ).reshape([B, C_out, size[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "c44e560d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 5])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "155f9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert th.allclose(f.conv1d(x, w), buck_conv1d(x, w))\n",
    "assert th.allclose(f.conv1d(x, w, stride=2), buck_conv1d(x, w, stride=2))\n",
    "assert th.allclose(f.conv1d(x, w, dilation=2), buck_conv1d(x, w, dilation=2))\n",
    "assert th.allclose(f.conv1d(x, w, stride=2, dilation=2), buck_conv1d(x, w, stride=2, dilation=2))\n",
    "groups_W = th.randn(C_out, C_in // 2, WINDOW_SIZE)\n",
    "assert th.allclose(f.conv1d(x, groups_W, groups=2),\n",
    "                  buck_conv1d(x, groups_W, groups=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c3659",
   "metadata": {},
   "source": [
    "## `conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "2d288a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.arange(12).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "837b464f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1],\n",
       "          [ 4,  5]],\n",
       "\n",
       "         [[ 1,  2],\n",
       "          [ 5,  6]],\n",
       "\n",
       "         [[ 2,  3],\n",
       "          [ 6,  7]]],\n",
       "\n",
       "\n",
       "        [[[ 4,  5],\n",
       "          [ 8,  9]],\n",
       "\n",
       "         [[ 5,  6],\n",
       "          [ 9, 10]],\n",
       "\n",
       "         [[ 6,  7],\n",
       "          [10, 11]]]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.arange(12).reshape(3, 4).as_strided([2, 3, 2, 2], [4, 1, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "76c391b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "C_in = 4\n",
    "C_out = 4\n",
    "H = 10\n",
    "W = 1\n",
    "kH = 10\n",
    "kW = 1\n",
    "\n",
    "x_2d = th.randn(B, C_in, H, W)\n",
    "w_2d = th.randn(C_out, C_in, kH, kW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a3cdd2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1, 1])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.conv2d(x_2d, w_2d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c49fd15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 1, 1)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_stride = x_2d.stride()\n",
    "initial_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "25f3f560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 10, 1])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "21a25e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "strided_x = x_2d.as_strided([B, C_in, H - kH + 1, W - kW + 1, kH, kW], list(initial_stride) + [W, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "40b695f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buck_conv_result = th.einsum('bcxyij,dcij->bdxy', strided_x, w_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "cf912b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1, 1])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buck_conv_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d3371362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buck_conv2d(inp, weight, stride=1):\n",
    "    B, C_in, H, W = inp.shape\n",
    "    C_out, C_in2, kH, kW = weight.shape\n",
    "    dilation = 1\n",
    "    size = [B, C_in, (H - ((kH - 1) * dilation)) // stride, (W - ((kW - 1) * dilation)) // stride, kH, kW]\n",
    "\n",
    "    stride = list(inp.stride()) + [W * stride, 1 * stride]\n",
    "    strided_x = inp.as_strided(size=size, stride=stride)\n",
    "    \n",
    "    return th.einsum('bcxyij,dcij->bdxy', strided_x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e01aef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert th.allclose(buck_conv2d(x_2d, w_2d), f.conv2d(x_2d, w_2d))\n",
    "assert th.allclose(buck_conv2d(x_2d, w_2d, stride=2), f.conv2d(x_2d, w_2d, stride=2))\n",
    "# TODO: dilation, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3eb5b",
   "metadata": {},
   "source": [
    "Debugging tips:\n",
    "\n",
    "- Are there any numbers you can set to one?\n",
    "- Are there any special cases of conv2d that are closely related to something you've already done?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
